{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "使用改进梯度下降法求解第6题"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 初始化各参数\n",
    "from optimize_lib import *\n",
    "\n",
    "\n",
    "eps=1e-4\n",
    "def gradf(x):\n",
    "    return np.array([2*x[0]-4,8*x[1]-8])\n",
    "\n",
    "def f(x):\n",
    "    return x[0]**2+4*x[1]**2-4*x[0]-8*x[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用带动量的梯度下降法求解\n",
    "$v_t=\\mu*v_{t-1}+\\eta*g_t$\n",
    "\n",
    "初始$v_0=\\textbf{0}$，$x_{t+1}=x_{t}-v_t$\n",
    "\n",
    "式中，$\\mu$为动量，$\\eta$为学习率，$g$为梯度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代点和函数值：\n",
      "x        f(x)\n",
      "-------------\n",
      "[0. 0.]        0.0\n",
      "[0.04 0.08]        -0.7728\n",
      "[0.1152 0.2256]        -2.04874752\n",
      "[0.220576 0.418592]        -3.4815091783680003\n",
      "[0.35100288 0.63879744]        -4.7589393408294915\n",
      "[0.50136701 0.86587854]        -5.682144911199881\n",
      "[0.6666674  1.08098125]        -6.195992314359515\n",
      "[0.84210439 1.26809519]        -6.371777642714598\n",
      "[1.0231556  1.41505011]        -6.35670862600295\n",
      "[1.20563857 1.51410554]        -6.311771896997085\n",
      "[1.38576048 1.56212698]        -6.358762840481424\n",
      "[1.56015498 1.56037612]        -6.550450784183426\n",
      "[1.72590694 1.51397025]        -6.868211308267139\n",
      "[1.88056556 1.43108735]        -7.242390185810616\n",
      "[2.02214701 1.32200576]        -7.584758679716531\n",
      "[2.14912737 1.19807186]        -7.820831182250096\n",
      "[2.26042715 1.0706856 ]        -7.912191882413888\n",
      "[2.35538841 0.95038312]        -7.8638517410471716\n",
      "[2.43374577 0.84608024]        -7.717099435774104\n",
      "[2.49559248 0.76452123]        -7.532587081281607\n",
      "[2.54134268 0.70995642]        -7.370446990826331\n",
      "[2.571691   0.68405158]        -7.273875781490473\n",
      "[2.58757066 0.68601309]        -7.260409605339993\n",
      "[2.59011095 0.71289741]        -7.322057478332551\n",
      "[2.58059499 0.7600615 ]        -7.432627528466586\n",
      "[2.56041872 0.82170427]        -7.558773377549236\n",
      "[2.53105171 0.89144641]        -7.670848552525046\n",
      "[2.49400037 0.96289863]        -7.75045759104379\n",
      "[2.45077415 1.03017373]        -7.793160850136021\n",
      "[2.40285507 1.08830743]        -7.806514983555269\n",
      "[2.3516708  1.13356316]        -7.80497117604145\n",
      "[2.29857153 1.16360827]        -7.803784374557203\n",
      "[2.24481077 1.1775602 ]        -7.813957183502167\n",
      "[2.19152986 1.17591213]        -7.839536004054011\n",
      "[2.13974645 1.16035589]        -7.87761488382192\n",
      "[2.09034645 1.1335268 ]        -7.920519889210977\n",
      "[2.04407952 1.09869848]        -7.959091434001284\n",
      "[2.0015577  1.05945711]        -7.985856979856347\n",
      "[1.9632569  1.01938331]        -7.997147093222471\n",
      "[1.92952104 0.98176623]        -7.993702835205032\n",
      "[1.90056835 0.94936955]        -7.979859579250694\n",
      "[1.87649956 0.92426298]        -7.96180325862201\n",
      "[1.85730766 0.90772603]        -7.9455809536326525\n",
      "[1.8428888  0.90022469]        -7.935495619000017\n",
      "[1.83305404 0.90145551]        -7.9332849795267455\n",
      "[1.82754168 0.9104468 ]        -7.938179029439232\n",
      "[1.82602973 0.92570323]        -7.94765430170462\n",
      "[1.82814837 0.94537775]        -7.958532656103245\n",
      "[1.83349218 0.9674546 ]        -7.96803833430476\n",
      "[1.84163177 0.9899274 ]        -7.974513674488289\n",
      "[1.85212476 1.01095872]        -7.97765254022041\n",
      "[1.86452596 1.02901022]        -7.978280414363841\n",
      "[1.87839652 1.04293575]        -7.977838681059009\n",
      "[1.89331209 1.05203386]        -7.977787599773093\n",
      "[1.90886987 1.05605946]        -7.9791246480731175\n",
      "[1.92469447 1.05519774]        -7.982141916153964\n",
      "[1.94044272 1.05000637]        -7.986450382133641\n",
      "[1.95580729 1.04133363]        -7.991213128565606\n",
      "[1.97051926 1.03022147]        -7.995477536054883\n",
      "[1.98434964 1.01780281]        -7.998487305527215\n",
      "[1.99711   1.0052018]        -7.999883413146719\n",
      "[2.00865211 0.99344474]        -7.999753254978253\n",
      "[2.01886698 0.9833878 ]        -7.998540176788467\n",
      "[2.02768302 0.97566554]        -7.99686498666849\n",
      "[2.03506379 0.97066226]        -7.995327718283577\n",
      "[2.04100521 0.96850633]        -7.994351166397622\n",
      "[2.04553239 0.96908548]        -7.994103971367509\n",
      "[2.0486962  0.97207988]        -7.994510547897486\n",
      "[2.0505697  0.97700845]        -7.995328259642503\n",
      "[2.05124446 0.98328349]        -7.996256237739078\n",
      "[2.05082686 0.99026834]        -7.997037809756903\n",
      "[2.04943448 0.99733324]        -7.9975277861816245\n",
      "[2.04719264 1.00390499]        -7.997711858518546\n",
      "[2.04423114 1.00950717]        -7.997682060976867\n",
      "[2.04068117 1.01378856]        -7.997584545549838\n",
      "[2.03667256 1.01653872]        -7.997561006013109\n",
      "[2.03233137 1.01769077]        -7.997702829205075\n",
      "[2.02777767 1.01731235]        -7.9980295309715626\n",
      "[2.02312379 1.01558679]        -7.998493498715314\n",
      "[2.01847282 1.01278684]        -7.9990047422922945\n",
      "[2.01391749 1.00924393]        -7.999464502304063\n",
      "[2.00953934 1.00531581]        -7.9997959697821965\n",
      "[2.00540822 1.00135523]        -7.999963404580214\n",
      "[2.00158205 0.99768229]        -7.99997600999174\n",
      "[1.99810685 0.99456206]        -7.999878131267048\n",
      "[1.99501704 0.99218889]        -7.999731116379369\n",
      "[1.99233587 0.99067793]        -7.999593656804376\n",
      "[1.99007609 0.99006382]        -7.999506605700685\n",
      "[1.98824078 0.99030603]        -7.999485828139152\n",
      "[1.98682418 0.99129953]        -7.9995236046553035\n",
      "[1.98581275 0.99288971]        -7.999596497294486\n",
      "[1.98518622 0.99488971]        -7.999676091330908\n",
      "[1.98491861 0.99709852]        -7.9997388772936935\n",
      "[1.98497939 0.99931857]        -7.999772523866859\n",
      "[1.9853345  1.00137114]        -7.99977740315476\n",
      "[1.98594742 1.00310875]        -7.999763867582828\n",
      "[1.98678009 1.0044239 ]        -7.999746950294776\n",
      "[1.9877939  1.00525363]        -7.999740608520881\n",
      "[1.98895044 1.00558009]        -7.999753357552751\n",
      "[1.99021232 1.0054275 ]        -7.999786370340829\n",
      "[1.99154377 1.00485597]        -7.999834170479476\n",
      "[1.9929112  1.00395311]        -7.999887240522181\n",
      "[1.99428366 1.00282429]        -7.99993541695096\n",
      "[1.9956332  1.00158241]        -7.999970914976617\n",
      "[1.99693513 1.00033813]        -7.999990149233888\n",
      "[1.99816815 0.99919122]        -7.999994027831991\n",
      "[1.99931452 0.9982237 ]        -7.999986909204858\n",
      "[2.00035995 0.99749504]        -7.999974771234989\n",
      "[2.00129365 0.99703965]        -7.999963271747065\n",
      "[2.0021081  0.99686662]        -7.999956283623862\n",
      "[2.00279894 0.99696156]        -7.999955237542825\n",
      "[2.00336472 0.99729009]        -7.9999593041608525\n",
      "[2.00380663 0.99780255]        -7.99996619448269\n",
      "[2.00412822 0.99843957]        -7.999973218046935\n",
      "[2.00433508 0.99913772]        -7.999978232965756\n",
      "[2.00443455 0.99983503]        -7.999980225890744\n",
      "[2.00443539 1.00047581]        -7.99997942174458\n",
      "[2.00434743 1.00101445]        -7.999976983389397\n",
      "[2.00418132 1.00141807]        -7.999974472849342\n",
      "[2.0039482  1.00166788]        -7.999973284421545\n",
      "[2.00365942 1.00175928]        -7.9999742283568125\n",
      "[2.00332634 1.0017008 ]        -7.999977364641923\n",
      "[2.00296003 1.0015121 ]        -7.9999820924414315\n",
      "[2.00257116 1.0012213 ]        -7.999987422834959\n",
      "[2.00216975 1.00086188]        -7.9999923208429955\n",
      "[2.00176508 1.00046945]        -7.999996002945091\n",
      "[2.00136558 1.00007871]        -7.999998110404105\n",
      "[2.00097872 0.99972074]        -7.999998730169966\n",
      "[2.00061097 0.99942092]        -7.999998285361439\n",
      "[2.00026778 0.9991974 ]        -7.999997351612592\n",
      "[1.99995355 0.99906044]        -7.9999964667429\n",
      "[1.99967167 0.99901234]        -7.999995990319421\n",
      "[1.99942455 0.99904807]        -7.999996044137903\n",
      "[1.99921364 0.99915637]        -7.999996534815746\n",
      "[1.99903956 0.99932134]        -7.999997235229996\n",
      "[1.99890209 0.9995241 ]        -7.999997888679031\n",
      "[1.99880033 0.99974466]        -7.999998299993314\n",
      "[1.99873274 0.99996359]        -7.999998388736832\n",
      "[1.99869725 1.00016354]        -7.999998195853804\n",
      "[1.99869136 1.00033041]        -7.999997850783012\n",
      "[1.99871224 1.00045416]        -7.999997516619691\n",
      "[1.99875678 1.00052921]        -7.999997334179877\n",
      "[1.99882174 1.00055441]        -7.999997382225884\n",
      "[1.99890376 1.00053274]        -7.999997663024781\n",
      "[1.99899951 1.00047062]        -7.9999981131014\n",
      "[1.99910569 1.00037706]        -7.999998631524482\n",
      "[1.99921914 1.00026269]        -7.999999114236515\n",
      "[1.99933686 1.00013874]        -7.999999483249596\n",
      "[1.99945607 1.00001609]        -7.999999703108474\n",
      "[1.99957424 0.99990442]        -7.999999782187777\n",
      "[1.99968911 0.99981156]        -7.999999761308108\n",
      "[1.99979871 0.99974306]        -7.9999996954117325\n",
      "[1.99990138 0.99970197]        -7.9999996349805595\n",
      "[1.99999575 0.99968883]        -7.999999612666618\n",
      "[2.00008076 0.99970189]        -7.9999996380071225\n",
      "[2.00015567 0.9997375 ]        -7.99999970014748\n",
      "[2.00021996 0.99979055]        -7.999999776137978\n",
      "[2.00027343 0.99985505]        -7.999999841190471\n",
      "[2.00031609 0.99992469]        -7.999999877404841\n",
      "[2.00034815 0.9999934 ]        -7.999999878614907\n",
      "[2.00037005 1.00005576]        -7.999999850625583\n",
      "[2.00038236 1.00010743]        -7.9999998076416325\n",
      "[2.00038578 1.00014533]        -7.999999766685175\n",
      "[2.00038115 1.00016782]        -7.999999742067988\n",
      "[2.00036936 1.00017463]        -7.999999741583707\n",
      "[2.00035137 1.00016679]        -7.9999997652609505\n",
      "[2.00032814 1.0001464 ]        -7.999999806597263\n",
      "[2.00030067 1.00011633]        -7.999999855468676\n",
      "[2.00026994 1.00007996]        -7.999999901559937\n",
      "[2.00023688 1.00004083]        -7.999999937219393\n",
      "[2.00020239 1.00000235]        -7.999999959015751\n",
      "[2.0001673  0.99996752]        -7.999999967791276\n",
      "[2.00013238 0.99993878]        -7.999999967486442\n",
      "[2.00009829 0.99991781]        -7.999999963319282\n",
      "[2.00006566 0.99990552]        -7.99999995997965\n",
      "[2.00003497 0.99990201]        -7.9999999603657\n",
      "[2.00000665 0.99990669]        -7.999999965126381\n",
      "[1.99998103 0.99991836]        -7.999999972982946\n",
      "[1.99995835 0.99993541]        -7.999999981575796\n",
      "[1.99993877 0.99995591]        -7.999999988475744\n",
      "[1.99992238 0.99997789]        -7.999999992019718\n",
      "[1.99990917 0.99999944]        -7.999999991749529\n",
      "[1.99989911 1.00001888]        -7.99999998839435\n",
      "[1.99989207 1.00003487]        -7.999999983486423\n",
      "[1.99988789 1.00004647]        -7.999999978793338\n",
      "[1.99988637 1.00005319]        -7.999999975771371\n",
      "[1.99988727 1.00005498]        -7.999999975200354\n",
      "[1.99989034 1.0000522 ]        -7.999999977076763\n",
      "[1.9998953  1.00004552]        -7.9999999807507525\n",
      "[1.99990185 1.00003586]        -7.999999985223072\n",
      "[1.99990971 1.0000243 ]        -7.999999989486083\n",
      "[1.9999186  1.00001196]        -7.999999992801619\n",
      "[1.99992822 0.99999989]        -7.99999999484719\n",
      "[1.99993831 0.99998903]        -7.999999995713633\n",
      "[1.99994863 0.99998014]        -7.9999999957842425\n",
      "[1.99995895 0.99997373]        -7.999999995554411\n",
      "[1.99996905 0.99997006]        -7.999999995456836\n",
      "[1.99997876 0.99996915]        -7.999999995742965\n",
      "[1.99998793 0.9999708 ]        -7.9999999964446955\n",
      "[1.99999642 0.99997463]        -7.999999997411688\n",
      "[2.00000413 0.99998009]        -7.99999999839798\n",
      "[2.00001099 0.99998661]        -7.999999999161881\n",
      "[2.00001695 0.99999354]        -7.999999999546069\n"
     ]
    }
   ],
   "source": [
    "x=np.array([0.,0.])\n",
    "momentum=0.9    # 动量\n",
    "lr=0.01 #学习率\n",
    "res_x,f_res=momentum_gd(x,gradf,lr,momentum,eps,f)\n",
    "print('迭代点和函数值：')\n",
    "print('x        f(x)')\n",
    "print('-------------')\n",
    "for i in range(len(res_x)):\n",
    "    print(res_x[i]+'        '+f_res[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "带动量的梯度下降法最后趋向于$[2,1]$，与第6题的结果相同，\n",
    "但迭代次数根据动量、学习率和eps的取值不同导致其收敛的快慢有所差异"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "自适应梯度(Adagrad)求解，设定初始$n=(0,0)^T$，进行如下运算:\n",
    "\n",
    "$ n_t=n_{t-1}+g_t^2$\n",
    "\n",
    "$\\Delta x_t=-\\frac{\\eta}{\\sqrt{n_t+\\epsilon}}*g_t$\n",
    "\n",
    "式中所有运算法都是按向量的每一个元素进行运算，$\\eta$为学习率，$g$为梯度，$\\epsilon$防止向量变为$\\textbf{0}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代点和函数值：\n",
      "x        f(x)\n",
      "-------------\n",
      "[0. 0.]        0.0\n",
      "[0.89999719 0.8999993 ]        -6.7499932500197755\n",
      "[1.33372387 0.9895532 ]        -7.555639580054047\n",
      "[1.58590965 0.99890815]        -7.828524411830645\n",
      "[1.74031906 0.99988588]        -7.932565759459997\n",
      "[1.83659539 0.99998807]        -7.973298933186786\n",
      "[1.89704062 0.99999875]        -7.989399366895745\n",
      "[1.93509242 0.99999987]        -7.995787005845879\n",
      "[1.95907249 0.99999999]        -7.99832493882063\n",
      "[1.974191 1.      ]        -7.999333895607375\n",
      "[1.98372424 1.        ]        -7.999735099690255\n",
      "[1.98973599 1.        ]        -7.999894650134671\n",
      "[1.99352716 1.        ]        -7.999958102315981\n",
      "[1.99591799 1.        ]        -7.9999833372052604\n",
      "[1.99742574 1.        ]        -7.999993373161515\n",
      "[1.99837657 1.        ]        -7.999997364486708\n",
      "[1.99897621 1.        ]        -7.999998951848286\n",
      "[1.99935436 1.        ]        -7.999999583146808\n",
      "[1.99959283 1.        ]        -7.999999834216183\n",
      "[1.99974323 1.        ]        -7.999999934067258\n",
      "[1.99983807 1.        ]        -7.999999973778341\n",
      "[1.99989788 1.        ]        -7.999999989571564\n",
      "[1.9999356 1.       ]        -7.999999995852578\n",
      "[1.99995939 1.        ]        -7.999999998350558\n"
     ]
    }
   ],
   "source": [
    "x=np.array([0.,0.])\n",
    "lr=0.9 #学习率\n",
    "mineps=1e-4\n",
    "res_x,f_res=adagrad(x,gradf,lr,mineps,eps,f)\n",
    "print('迭代点和函数值：')\n",
    "print('x        f(x)')\n",
    "print('-------------')\n",
    "for i in range(len(res_x)):\n",
    "    print(res_x[i]+'        '+f_res[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "一开始学习率设置成了0.01，导致算法很长时间还没收敛\n",
    "\n",
    "AdaGrad根据自变量在每个维度的梯度值的大小来调整各个维度上的学习率，从而避免统⼀的学习率难以适应所有维度的问题。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}